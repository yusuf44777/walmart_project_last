# ğŸ—ï¸ Sistem Mimarisi

> **Teknik Alt YapÄ±** - Walmart AI Content Generator'Ã¼n mimari tasarÄ±mÄ±

## ğŸ“ Genel Mimari

```mermaid
graph TB
    subgraph "Frontend Layer"
        A[Streamlit UI] --> B[User Interface]
        B --> C[Input Forms]
        C --> D[Results Display]
    end
    
    subgraph "Application Layer"
        E[walmart.py] --> F[API Wrapper]
        F --> G[Content Generator]
        G --> H[Data Processor]
    end
    
    subgraph "AI/ML Layer"
        I[Ollama Local] --> J[llama3.1:8b]
        K[OpenAI Cloud] --> L[GPT-3.5/4]
        M[Custom Models] --> N[Walmart-GPT]
    end
    
    subgraph "Data Layer"
        O[training_data.json] --> P[Model Training]
        Q[Export Files] --> R[TXT/JSONL]
    end
    
    A --> E
    F --> I
    F --> K
    F --> M
    H --> O
    G --> Q
```

## ğŸ”§ Teknoloji Stack'i

### Frontend
| Teknoloji | Versiyon | Rol | Neden SeÃ§ildi |
|-----------|----------|-----|---------------|
| **Streamlit** | 1.25+ | Web UI Framework | HÄ±zlÄ± prototipleme, Python-native |
| **HTML/CSS** | - | Styling | Custom component styling |
| **JavaScript** | ES6 | Client-side logic | Interactive elements |

### Backend
| Teknoloji | Versiyon | Rol | Neden SeÃ§ildi |
|-----------|----------|-----|---------------|
| **Python** | 3.11+ | Core Language | AI/ML ecosystem, libraries |
| **Requests** | 2.31+ | HTTP Client | API communication |
| **Pandas** | 2.0+ | Data Processing | Data manipulation, analytics |
| **JSON** | Native | Data Format | Lightweight, human-readable |

### AI/ML
| Platform | Model | KullanÄ±m | AvantajlarÄ± |
|----------|-------|----------|-------------|
| **Ollama** | llama3.1:8b | Local LLM | Ãœcretsiz, privacy, offline |
| **OpenAI** | GPT-3.5/4 | Cloud LLM | High quality, reliable |
| **Custom** | Walmart-GPT | Fine-tuned | Domain-specific, optimized |

## ğŸŒŠ Data Flow DiagramÄ±

```mermaid
sequenceDiagram
    participant U as User
    participant UI as Streamlit UI
    participant App as Application
    participant API as AI Model API
    participant DB as Data Storage
    
    U->>UI: Enter product info
    UI->>App: Validate input
    App->>API: Send prompt request
    API->>App: Return generated content
    App->>UI: Format response
    UI->>U: Display results
    App->>DB: Save training data
    U->>UI: Export content
    UI->>U: Download file
```

## ğŸ“¦ ModÃ¼l YapÄ±sÄ±

### Ana Uygulama (walmart.py)
```python
â”œâ”€â”€ Environment Detection
â”‚   â”œâ”€â”€ get_ollama_base_url()
â”‚   â”œâ”€â”€ is_local_environment()
â”‚   â””â”€â”€ cloud_environment_check()
â”‚
â”œâ”€â”€ AI Model Integration
â”‚   â”œâ”€â”€ ollama_integration()
â”‚   â”œâ”€â”€ openai_integration()
â”‚   â””â”€â”€ model_selection_logic()
â”‚
â”œâ”€â”€ Content Generation
â”‚   â”œâ”€â”€ generate_content()
â”‚   â”œâ”€â”€ format_walmart_output()
â”‚   â””â”€â”€ quality_validation()
â”‚
â”œâ”€â”€ Data Management
â”‚   â”œâ”€â”€ save_training_data()
â”‚   â”œâ”€â”€ export_functions()
â”‚   â””â”€â”€ data_analytics()
â”‚
â””â”€â”€ UI Components
    â”œâ”€â”€ sidebar_controls()
    â”œâ”€â”€ main_interface()
    â””â”€â”€ results_display()
```

### YardÄ±mcÄ± ModÃ¼ller
```python
â”œâ”€â”€ advanced_model_training.py
â”‚   â”œâ”€â”€ data_quality_analysis()
â”‚   â”œâ”€â”€ model_performance_metrics()
â”‚   â””â”€â”€ training_pipeline()
â”‚
â”œâ”€â”€ create_walmart_model.py
â”‚   â”œâ”€â”€ modelfile_generation()
â”‚   â”œâ”€â”€ fine_tuning_process()
â”‚   â””â”€â”€ model_validation()
â”‚
â”œâ”€â”€ model_analytics.py
â”‚   â”œâ”€â”€ performance_tracking()
â”‚   â”œâ”€â”€ usage_statistics()
â”‚   â””â”€â”€ analytics_dashboard()
â”‚
â””â”€â”€ model_optimizer.py
    â”œâ”€â”€ parameter_tuning()
    â”œâ”€â”€ performance_optimization()
    â””â”€â”€ resource_management()
```

## ğŸ”„ API Entegrasyon Mimarisi

### Ollama (Local) Integration
```python
class OllamaIntegration:
    def __init__(self):
        self.base_url = "http://localhost:11434"
        self.timeout = 30
        
    def health_check(self):
        """Ollama servis durumu kontrolÃ¼"""
        
    def list_models(self):
        """Mevcut modelleri listele"""
        
    def generate_content(self, prompt):
        """Ä°Ã§erik Ã¼retimi"""
        
    def stream_response(self, prompt):
        """Streaming yanÄ±t"""
```

### OpenAI Integration
```python
class OpenAIIntegration:
    def __init__(self, api_key):
        self.client = openai.OpenAI(api_key=api_key)
        self.model = "gpt-3.5-turbo"
        
    def validate_api_key(self):
        """API key doÄŸrulama"""
        
    def generate_content(self, prompt):
        """Ä°Ã§erik Ã¼retimi"""
        
    def estimate_cost(self, prompt):
        """Maliyet hesaplama"""
```

## ğŸ’¾ Veri Mimarisi

### Training Data Schema
```json
{
  "timestamp": "2025-08-14T10:30:00Z",
  "input": {
    "product_name": "string",
    "features": ["string"],
    "category": "string",
    "user_preferences": {}
  },
  "output": {
    "title": "string",
    "features_formatted": ["string"],
    "description": "string",
    "seo_keywords": ["string"]
  },
  "metadata": {
    "model_used": "string",
    "generation_time": "float",
    "quality_score": "float",
    "user_rating": "int"
  }
}
```

### File Structure
```
â”œâ”€â”€ training_data.json      # Ana eÄŸitim verisi
â”œâ”€â”€ model_performance.db    # SQLite performans DB
â”œâ”€â”€ user_preferences.json   # KullanÄ±cÄ± ayarlarÄ±
â””â”€â”€ export_history.json     # Export geÃ§miÅŸi
```

## ğŸš€ Deployment Mimarisi

### Local Development
```bash
â”œâ”€â”€ Python Virtual Environment
â”œâ”€â”€ Ollama Local Service
â”œâ”€â”€ Streamlit Dev Server
â””â”€â”€ File-based Data Storage
```

### Cloud Production
```bash
â”œâ”€â”€ Streamlit Cloud/Heroku
â”œâ”€â”€ Cloud-based LLM APIs
â”œâ”€â”€ Database Service (PostgreSQL)
â””â”€â”€ File Storage (AWS S3)
```

## ğŸ”’ GÃ¼venlik Mimarisi

### API Key Management
```python
# Environment Variables
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
CLOUD_OLLAMA_URL = os.getenv('CLOUD_OLLAMA_URL')

# Session State (Temporary)
st.session_state.api_key = "temporary_storage"

# Encryption (Production)
from cryptography.fernet import Fernet
key = Fernet.generate_key()
```

### Rate Limiting
```python
import time
from functools import wraps

def rate_limit(calls_per_minute=60):
    def decorator(func):
        last_called = {}
        
        @wraps(func)
        def wrapper(*args, **kwargs):
            # Rate limiting logic
            pass
        return wrapper
    return decorator
```

## ğŸ“Š Monitoring & Analytics

### Performance Metrics
```python
class PerformanceMonitor:
    def __init__(self):
        self.metrics = {
            'response_time': [],
            'success_rate': 0,
            'error_count': 0,
            'user_satisfaction': []
        }
    
    def log_request(self, start_time, end_time, success):
        """Ä°stek metriklerini logla"""
        
    def generate_report(self):
        """Performans raporu oluÅŸtur"""
```

### Usage Analytics
```python
class UsageAnalytics:
    def track_feature_usage(self, feature_name):
        """Ã–zellik kullanÄ±m takibi"""
        
    def user_behavior_analysis(self):
        """KullanÄ±cÄ± davranÄ±ÅŸ analizi"""
        
    def generate_insights(self):
        """Ä°statistiksel insights"""
```

## ğŸ”§ KonfigÃ¼rasyon YÃ¶netimi

### Environment-based Config
```python
import os
from dataclasses import dataclass

@dataclass
class Config:
    # Environment detection
    environment: str = os.getenv('ENVIRONMENT', 'development')
    
    # API Settings
    ollama_base_url: str = os.getenv('OLLAMA_BASE_URL', 'http://localhost:11434')
    openai_api_key: str = os.getenv('OPENAI_API_KEY', '')
    
    # Application Settings
    max_response_time: int = int(os.getenv('MAX_RESPONSE_TIME', '30'))
    enable_data_collection: bool = os.getenv('ENABLE_DATA_COLLECTION', 'true').lower() == 'true'
    
    # Model Settings
    default_model: str = os.getenv('DEFAULT_MODEL', 'ollama')
    max_tokens: int = int(os.getenv('MAX_TOKENS', '2000'))
```

## ğŸ”„ SÃ¼rÃ¼m YÃ¶netimi

### Model Versioning
```python
class ModelVersionManager:
    def __init__(self):
        self.versions = {
            'walmart-gpt-basic': '1.0.0',
            'walmart-gpt-advanced': '1.1.0',
            'walmart-gpt-expert': '1.2.0'
        }
    
    def get_latest_version(self, model_name):
        """En son model versiyonunu getir"""
        
    def version_compatibility_check(self, model, version):
        """Versiyon uyumluluk kontrolÃ¼"""
```

## ğŸ“ˆ Ã–lÃ§eklenebilirlik

### Horizontal Scaling
- **Load Balancer**: Multiple Streamlit instances
- **Database Sharding**: User-based data partitioning
- **Caching Layer**: Redis for frequent requests
- **CDN**: Static assets delivery

### Vertical Scaling
- **Memory Optimization**: Efficient data structures
- **CPU Utilization**: Parallel processing
- **GPU Support**: AI model acceleration
- **SSD Storage**: Fast I/O operations

---

*ğŸ—ï¸ Mimari versiyon: 2.0 | ğŸ“… Son gÃ¼ncelleme: 14 AÄŸustos 2025 | ğŸ‘¨â€ğŸ’» Architect: System Design Team*
